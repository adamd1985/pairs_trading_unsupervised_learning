{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pairs Traiding through Unsupervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "MIN_YEAR=2018 # 1980\n",
    "MAX_YEAR=2021\n",
    "CHUNKS = 10000\n",
    "\n",
    "FILEPATH = f\"./data/historic_characteristics.csv\"\n",
    "FILEPATH_PARQ = f\"./data/historic_characteristics_{MIN_YEAR}_{MAX_YEAR}.parquet\"\n",
    "FILEPATH_MOM_PARQ = f\"./data/data_mom_{MIN_YEAR}_{MAX_YEAR}.parquet\"\n",
    "FILEPATH_CLEAN_PARQ = f\"./data/data_cleaning_{MIN_YEAR}_{MAX_YEAR}.parquet\"\n",
    "FILEPATH_PRE_PARQ = f\"./data/data_preprocessed_{MIN_YEAR}_{MAX_YEAR}.parquet\"\n",
    "\n",
    "CLUSTERS_FILEPATH = f\"./data/clusters_data_{MIN_YEAR}_{MAX_YEAR}.pkl\"\n",
    "CLUSTERS_MEM_FILEPATH = f\"./data/clusters_mem_data_{MIN_YEAR}_{MAX_YEAR}.pkl\"\n",
    "SIGNALS_FILEPATH = f\"./data/signals_{MIN_YEAR}_{MAX_YEAR}.pkl\"\n",
    "PCA_FILEPATH = f\"./data/pca_{MIN_YEAR}_{MAX_YEAR}.pkl\"\n",
    "\n",
    "FEATURES = [\n",
    "    \"DATE\", \"absacc\", \"acc\", \"aeavol\", \"age\", \"agr\", \"baspread\", \"beta\", \"betasq\", \"bm\",\n",
    "    \"bm_ia\", \"cash\", \"cashdebt\", \"cashpr\", \"cfp\", \"cfp_ia\", \"chatoia\", \"chcsho\", \"chempia\",\n",
    "    \"chinv\", \"chmom\", \"chpmia\", \"chtx\", \"cinvest\", \"convind\", \"currat\", \"depr\", \"divi\",\n",
    "    \"divo\", \"dolvol\", \"dy\", \"ear\", \"egr\", \"ep\", \"gma\", \"herf\", \"hire\", \"idiovol\", \"ill\",\n",
    "    \"indmom\", \"invest\", \"lev\", \"lgr\", \"maxret\", \"mom1m\", \"ms\", \"mve_ia\", \"mvel1\", \"nincr\",\n",
    "    \"operprof\", \"pchcapx_ia\", \"pchcurrat\", \"pchdepr\", \"pchgm_pchsale\", \"pchquick\",\n",
    "    \"pchsale_pchrect\", \"pctacc\", \"permno\", \"pricedelay\", \"ps\", \"quick\", \"rd\", \"retvol\",\n",
    "    \"roaq\", \"roeq\", \"roic\", \"rsup\", \"salecash\", \"salerec\", \"securedind\", \"sgr\", \"sic2\",\n",
    "    \"sin\", \"sp\", \"std_dolvol\", \"std_turn\", \"tang\", \"tb\", \"turn\", \"zerotrade\"\n",
    "]\n",
    "WINDOW = 48\n",
    "MOM_FEATURES = [f\"mom{i}m\" for i in range(1, WINDOW + 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling\n",
    "\n",
    "## Parquet Dataset Creation\n",
    "\n",
    "The dataset is large, around 3GB of company characteristics from 1985 to 2021. This dataset has been currated for the papers [\"Empirical Asset Pricing via Machine Learning\"](https://dachxiu.chicagobooth.edu/download/ML.pdf)(2018) and [\"Autoencoder Asset Pricing Models.\" ](https://www.sciencedirect.com/science/article/abs/pii/S0304407620301998)(2019) by Shihao Gu, Bryan Kelly and Dacheng Xiu. The raw format is available for download from the authors [personal website](https://sites.google.com/view/agoyal145) (or reach out to me for a currated dataset). The dataset has 94 1 month Lagged Firm Characteristics (as the CRSP releases these with a month delay, from the notes in their papers). Note that this CRSP datasets don't have tickers or company names, but use a permanent indentifier instead, which if you have a bloomberg terminal or access to a research site that brokers this data, you can easily convert to the company ticker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import dask\n",
    "dask.config.set({'dataframe.query-planning': True})\n",
    "import dask.dataframe as dd\n",
    "\n",
    "if not os.path.exists(FILEPATH_PARQ):\n",
    "    chars_df = pd.read_csv(FILEPATH)[FEATURES]\n",
    "    chars_df['DATE'] = pd.to_datetime(chars_df['DATE'], format='%Y%m%d')\n",
    "    chars_df = chars_df[(chars_df['DATE'].dt.year >= MIN_YEAR) & (chars_df['DATE'].dt.year <= MAX_YEAR)]\n",
    "    chars_df = chars_df.sort_values(\"DATE\")\n",
    "    chars_df.to_parquet(FILEPATH_PARQ, index=False, compression=\"snappy\")\n",
    "else:\n",
    "    chars_df = pd.read_parquet(FILEPATH_PARQ)\n",
    "\n",
    "chars_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanitinzation and Feature Engineering\n",
    "\n",
    "To sanitinize we drop any company with insufficiant data to fill a window, and we fill any missing characteristic with the median of that window. We then perform a rolling window to calculate the MOM factor for 2 to 64 months, the data already has a rolling 1 month momentum. To read about momentum stratgies check out the article [Momentum and Reversion Trading Signals Analysis](https://medium.com/call-for-atlas/momentum-and-reversion-the-poor-mans-trading-strategies-9b8e1e6d3496).\n",
    "\n",
    "Imputting the MOM features for 49 months:\n",
    "\n",
    "For $i = 1, mom_i = r_{t-1}, \\quad i = 1$ where $r_{t-1}$ denotes the return in the previous month.\n",
    "\n",
    "For $i > 1$, we calculate the momentum over a window of $i$ months is given by:\n",
    "$$\n",
    "mom_i = \\left( \\prod_{j=t-i}^{t-2} (r_j + 1) \\right) - 1, \\quad i \\in \\{2, \\ldots, 48\\},\n",
    "$$\n",
    "where \\(r_j\\) denotes the return in month \\(j\\).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_with_median(group):\n",
    "    rolling_median = group.rolling(window=WINDOW, min_periods=1).median()\n",
    "    group= group.fillna(rolling_median).bfill()\n",
    "    return group\n",
    "\n",
    "if not os.path.exists(FILEPATH_PRE_PARQ):\n",
    "    valid_groups = chars_df.groupby('permno').filter(lambda x: len(x) >= WINDOW and x[MOM_FEATURES[0]].isna().sum() <= 2)\n",
    "    for i in tqdm(range(2, WINDOW + 1), desc=\"moms\"):\n",
    "        rolling_func = lambda x: (x + 1).rolling(window=i).apply(np.prod, raw=True) - 1\n",
    "        valid_groups[f'mom{i}m'] = valid_groups.groupby('permno')[MOM_FEATURES[0]].transform(rolling_func)\n",
    "\n",
    "    numerical_columns = valid_groups.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "    tqdm.pandas(desc=\"interpolate_with_median\")\n",
    "    valid_groups[numerical_columns]= valid_groups.groupby('permno')[numerical_columns].progress_transform(lambda x: interpolate_with_median(x))\n",
    "    valid_groups.to_parquet(FILEPATH_PRE_PARQ, index=False, compression=\"snappy\")\n",
    "    chars_df = valid_groups\n",
    "else:\n",
    "    chars_df = pd.read_parquet(FILEPATH_PRE_PARQ)\n",
    "\n",
    "chars_df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Firm Characteristics\n",
    "\n",
    "| Acronym  | Firm characteristic                                           | Acronym    | Firm characteristic                                       |\n",
    "|----------|--------------------------------------------------------------|------------|----------------------------------------------------------|\n",
    "| absacc   | Absolute accruals                                            | invest     | Capital expenditures and inventory                        |\n",
    "| acc      | Working capital accruals                                     | IPO        | New equity issue                                          |\n",
    "| aeavol   | Abnormal earnings announcement volume                        | lev        | Leverage                                                  |\n",
    "| age      | # years since first Compustat coverage                       | lgr        | Growth in long-term debt                                  |\n",
    "| agr      | Asset growth                                                  | maxret     | Maximum daily return                                      |\n",
    "| baspread | Bid-ask spread                                               | ms         | Financial statement score                                 |\n",
    "| beta     | Beta                                                         | mve        | Size                                                      |\n",
    "| betasq   | Beta squared                                                 | mve ia     | Industry-adjusted size                                    |\n",
    "| bm       | Book-to-market                                               | nincr      | Number of earnings increases                              |\n",
    "| bm ia    | Industry-adjusted book to market                             | operprof   | Operating profitability                                   |\n",
    "| cash     | Cash holdings                                                | pchcapx ia | Industry adjusted % change in capital expenditures        |\n",
    "| cashdebt | Cash flow to debt                                            | pchcurrat  | % change in current ratio                                 |\n",
    "| cashpr   | Cash productivity                                            | pchdepr    | % change in depreciation                                  |\n",
    "| cfp      | Cash flow to price ratio                                     | pchgm      | % change in gross margin                                  |\n",
    "| cfp ia   | Industry-adjusted cash flow to price ratio                   | pchsale    | % change in sales                                         |\n",
    "| chatoia  | Industry-adjusted change in asset turnover                   | pchquick   | % change in quick ratio                                   |\n",
    "| chcsho   | Change in shares outstanding                                 | pctacc     | Percent accruals                                          |\n",
    "| chempia  | Industry-adjusted change in employees                        | pricedelay | Price delay                                               |\n",
    "| chinv    | Change in inventory                                          | ps         | Financial statements score                                |\n",
    "| chmom    | Change in 6-month momentum                                   | quick      | Quick ratio                                               |\n",
    "| chpmia   | Industry-adjusted change in profit margin                    | rd         | R&D increase                                              |\n",
    "| chtx     | Change in tax expense                                        | retvol     | Return volatility                                         |\n",
    "| cinvest  | Corporate investment                                         | roaq       | Return on assets                                          |\n",
    "| convind  | Convertible debt indicator                                   | roeq       | Return on equity                                          |\n",
    "| currat   | Current ratio                                                | roic       | Return on invested capital                                |\n",
    "| depr     | Depreciation / PP&E                                          | rsup       | Revenue surprise                                          |\n",
    "| divi     | Dividend initiation                                          | sgr        | Sales growth                                              |\n",
    "| divo     | Dividend omission                                            | sin        | Sin stocks                                                |\n",
    "| dolvol   | Dollar trading volume                                        | SP         | Sales to price                                            |\n",
    "| dy       | Dividend to price                                            | std dolvol | Volatility of liquidity (dollar trading volume)          |\n",
    "| ear      | Earnings announcement return                                 | std turn   | Volatility of liquidity (share turnover)                  |\n",
    "| egr      | Growth in common shareholder equity                          | sue        | Unexpected quarterly earnings                             |\n",
    "| ep       | Earnings to price                                            | tang       | Debt capacity/firm tangibility                            |\n",
    "| gma      | Gross profitability                                          | tb         | Tax income to book income                                 |\n",
    "| herf     | Industry sales concentration                                 | turn       | Share turnover                                            |\n",
    "| hire     | Employee growth rate                                         | zerotrade  | Zero trading days                                         |\n",
    "| idiovol  | Idiosyncratic return volatility                              |            |                                                           |\n",
    "| ill      | Illiquidity                                                  |            |                                                           |\n",
    "| indmom   | Industry momentum                                            |            |                                                           |\n",
    "\n",
    "\n",
    "Additionally, there are PERMNO columns to ID the company, and a **SIC code** to ID the industry from [NAICS](https://www.naics.com/sic-codes-industry-drilldown/) to compliment the industires momentum **INDMOM**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For MOM - this is the equities' acceleration measure and is calculated as follows:\n",
    "\n",
    "$$\n",
    "\\text{MOM}_{\\text{1 month}} = \\left( \\frac{\\text{Price at End of Month} - \\text{Price at Start of Month}}{\\text{Price at Start of Month}} \\right) \\times 100\n",
    "$$\n",
    "\n",
    "Although we don't have a method to convert PERMNO to the actual stock and calculate its price, MOM already provides that change for 1 month."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dim Reduction with PCA\n",
    "\n",
    "We perform standardization and PCA at 95% variance, to center the data's means for the clustering algorithims and reduce its dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "MAX_VARIANCE = 0.99\n",
    "\n",
    "chars_pca_df = chars_df.copy()\n",
    "if os.path.exists(PCA_FILEPATH):\n",
    "    pca_result_df = pd.read_pickle(PCA_FILEPATH)\n",
    "else:\n",
    "    scaler = StandardScaler()\n",
    "    pca = PCA(MAX_VARIANCE)\n",
    "    features_df = chars_pca_df.drop(['DATE', 'permno'], axis=1).bfill()\n",
    "    pipeline = Pipeline([('scaler', scaler), ('pca', pca)])\n",
    "    pca_df = pipeline.fit_transform(features_df)\n",
    "\n",
    "    pca_result_df = pd.DataFrame(data=pca_df, index=chars_pca_df.index)\n",
    "    pca_components_cols = pca_result_df.columns\n",
    "    pca_result_df['permno'] = chars_pca_df['permno']\n",
    "    pca_result_df[MOM_FEATURES] = chars_pca_df[MOM_FEATURES]\n",
    "    pca_result_df['DATE'] = chars_pca_df['DATE']\n",
    "\n",
    "    pca_result_df.to_pickle(PCA_FILEPATH)\n",
    "\n",
    "pca_result_df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Agglomerative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "def train_clusters(pca_result_df):\n",
    "    models_dfs = []\n",
    "\n",
    "    cluster_membership = []\n",
    "    for month, data in tqdm(pca_result_df.groupby(\"DATE\"), desc=\"Processing months\"):\n",
    "        pca_data = data[pca_components_cols]\n",
    "        if len(pca_data) < 2:\n",
    "            print(f\"Skipping {month} due to insufficient data.\")\n",
    "            continue\n",
    "\n",
    "        neigh = NearestNeighbors(n_neighbors=2)\n",
    "        nbrs = neigh.fit(pca_data)\n",
    "        distances, _ = nbrs.kneighbors(pca_data)\n",
    "\n",
    "        distances = np.sort(distances, axis=0)\n",
    "        distances = distances[:, 1]\n",
    "        distance_alpha_thresh = np.percentile(distances, 30)\n",
    "        agg_model = AgglomerativeClustering(n_clusters=None, distance_threshold=distance_alpha_thresh, linkage='average')\n",
    "        agg_model.fit(pca_data)\n",
    "\n",
    "        cluster_df = pd.DataFrame(data['permno'].copy(), index=data.index)\n",
    "        cluster_df['Cluster'] = agg_model.labels_\n",
    "        cluster_df['DATE'] = month\n",
    "        cluster_df[MOM_FEATURES[0]] = data[MOM_FEATURES[0]]\n",
    "\n",
    "        cluster_membership.append(cluster_df)\n",
    "\n",
    "        models_dfs.append({'DATE': month, 'NumClusters': agg_model.n_clusters_})\n",
    "\n",
    "    models_df = pd.DataFrame(models_dfs)\n",
    "    cluster_membership_df = pd.concat(cluster_membership, ignore_index=False)\n",
    "\n",
    "    return models_df, cluster_membership_df\n",
    "\n",
    "if os.path.exists(CLUSTERS_FILEPATH) and os.path.exists(CLUSTERS_MEM_FILEPATH) :\n",
    "    models_df = pd.read_pickle(CLUSTERS_FILEPATH)\n",
    "    cluster_membership_df = pd.read_pickle(CLUSTERS_MEM_FILEPATH)\n",
    "else:\n",
    "    models_df, cluster_membership_df = train_clusters(pca_result_df)\n",
    "    models_df.to_pickle(CLUSTERS_FILEPATH)\n",
    "    cluster_membership_df.to_pickle(CLUSTERS_MEM_FILEPATH)\n",
    "\n",
    "pca_result_df['Cluster'] = cluster_membership_df['Cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trade Simulation\n",
    "\n",
    "The trade will take the following steps:\n",
    "1. Check that the security is in the cluster.\n",
    "2. Get cross-sectional standard dev.\n",
    "3. split into deciles.\n",
    "4. if first > last by > 1 std - there is a statarb opportunity.\n",
    "5. Select Long-Short for that month, and close securities from previous month which have reversed back to their normal distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statarb_signals(group):\n",
    "    rets = group[MOM_FEATURES[0]].mean()\n",
    "    std_dev = group[MOM_FEATURES[0]].std()\n",
    "    group['Decile'] = pd.qcut(group[MOM_FEATURES[0]], 10, labels=False, duplicates='drop') + 1\n",
    "\n",
    "    over_cond = (group['Decile'] == 10) & (group[MOM_FEATURES[0]] > rets + std_dev)\n",
    "    under_cond = (group['Decile'] == 1) & (group[MOM_FEATURES[0]] < rets - std_dev)\n",
    "    overs = set(group[over_cond]['permno'].tolist())\n",
    "    unders = set(group[under_cond]['permno'].tolist())\n",
    "\n",
    "    trade_ops = []\n",
    "    if overs or unders:\n",
    "        trade_ops.append({\n",
    "            'DATE': group['DATE_TRADE'].unique()[0],\n",
    "            'Cluster': group['Cluster'].tolist(),\n",
    "            'overs': overs,\n",
    "            'unders': unders\n",
    "            })\n",
    "\n",
    "    return trade_ops\n",
    "\n",
    "pca_result_df['DATE_TRADE'] = pca_result_df.groupby('permno')['DATE'].shift(-1).ffill()\n",
    "if os.path.exists(SIGNALS_FILEPATH):\n",
    "    trade_opportunities_df = pd.read_pickle(SIGNALS_FILEPATH)\n",
    "else:\n",
    "    trade_opportunities = pca_result_df.groupby(['DATE_TRADE', 'Cluster']).progress_apply(statarb_signals)\n",
    "    trade_opportunities = [item for sublist in trade_opportunities for item in sublist]\n",
    "    trade_opportunities_df = pd.DataFrame(trade_opportunities)\n",
    "    trade_opportunities_df.to_pickle(SIGNALS_FILEPATH)\n",
    "\n",
    "trade_opportunities_df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PnL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_trade_opportunities_df = trade_opportunities_df[\n",
    "    (trade_opportunities_df['overs'].apply(len) > 0) & (trade_opportunities_df['unders'].apply(len) > 0)\n",
    "]\n",
    "filtered_trade_opportunities_df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRADE_FEATURE = [\"DATE\"]\n",
    "\n",
    "asset_df = pca_result_df.reset_index()[['DATE', 'permno', MOM_FEATURES[0]]].copy()\n",
    "\n",
    "monthly_profit_loss = []\n",
    "\n",
    "trade_opportunities_df['prev_overs'] = trade_opportunities_df['overs'].shift(1).bfill()\n",
    "trade_opportunities_df['prev_unders'] = trade_opportunities_df['unders'].shift(1).bfill()\n",
    "trade_opportunities_df['overs_delta'] = trade_opportunities_df.apply(lambda row: row['prev_overs'].difference(row['overs']), axis=1)\n",
    "trade_opportunities_df['unders_delta'] = trade_opportunities_df.apply(lambda row: row['prev_unders'].difference(row['unders']), axis=1)\n",
    "\n",
    "overs_df = trade_opportunities_df[TRADE_FEATURE +  ['overs_delta']].explode('overs_delta').rename(columns={'overs_delta': 'permno'})\n",
    "unders_df = trade_opportunities_df[TRADE_FEATURE +  ['unders_delta']].explode('unders_delta').rename(columns={'unders_delta': 'permno'})\n",
    "\n",
    "overs_df = pd.merge(overs_df, asset_df, left_on=['DATE', 'permno'], right_on=['DATE', 'permno'])\n",
    "unders_df = pd.merge(unders_df, asset_df, left_on=['DATE', 'permno'], right_on=['DATE', 'permno'])\n",
    "\n",
    "unders_df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overs_df[overs_df[\"permno\"] == 79851]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unders_df[unders_df[\"permno\"] == 79851]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance\n",
    "\n",
    "Equal Weighted Returns:\n",
    "\n",
    "$$\n",
    "R_p = \\sum_{i=1}^{n} (w_i \\cdot r_i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overs_df = overs_df.groupby('DATE')[MOM_FEATURES[0]].mean()\n",
    "unders_df = unders_df.groupby('DATE')[MOM_FEATURES[0]].mean()\n",
    "\n",
    "overs_df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unders_df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_ret = overs_df.mul(-1).add(1).cumprod().sub(1)\n",
    "under_ret = unders_df.add(1).cumprod().sub(1)\n",
    "\n",
    "over_ret.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_ret.tail(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
